{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Exploring Keras library's role in computer vision. Load and convert images with Keras, how to use the MNIST handwritten image classification dataset and how to employ the ImageDataGenerator class."
      ],
      "metadata": {
        "id": "kC-gg8PtLBVq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWRg0PWLK3Sa",
        "outputId": "5ba5a8f8-9d48-4efa-f09b-e08981d333bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'computer-vision-course' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# clone github repo\n",
        "!git clone https://github.com/zaka-ai/computer-vision-course.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load an Image with Keras"
      ],
      "metadata": {
        "id": "tj-SmHmjLWfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading an image with the Keras API\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# load the image\n",
        "img_path = \"computer-vision-course/deep_learning/data/image1.jpg\"\n",
        "img = load_img(img_path)\n",
        "\n",
        "# report details about the image\n",
        "print(type(img))\n",
        "print(img.format)\n",
        "print(img.mode)\n",
        "print(img.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sbGAU62LW-O",
        "outputId": "8c98f8ff-5759-4e00-8a7a-b47943fa085a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
            "JPEG\n",
            "RGB\n",
            "(640, 360)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Convert an Image With Keras"
      ],
      "metadata": {
        "id": "h6agRffaLhei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of converting an image with the Keras API\n",
        "from tensorflow.keras.preprocessing.image import load_img \n",
        "from tensorflow.keras.preprocessing.image import img_to_array \n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "# load the image\n",
        "img_path = \"computer-vision-course/deep_learning/data/image1.jpg\"\n",
        "img = load_img(img_path)\n",
        "print(type(img))\n",
        "\n",
        "# convert to numpy array\n",
        "img_array = img_to_array(img) \n",
        "print(img_array.dtype)\n",
        "print(img_array.shape)\n",
        "\n",
        "# convert back to image\n",
        "img_pil = array_to_img(img_array)\n",
        "print(type(img))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhrodMkFLg8l",
        "outputId": "9ba309b2-12d6-43f2-dcdb-a213d71cd31d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
            "float32\n",
            "(360, 640, 3)\n",
            "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageDataGenerator Class"
      ],
      "metadata": {
        "id": "BRujweLaLqLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST Handwritten Image Classification Dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# summarize dataset shape\n",
        "print(\"Train\", trainX.shape, trainY.shape)\n",
        "print(\"Test\", testX.shape, testY.shape)\n",
        "\n",
        "# summarize pixel values\n",
        "print(\"Train\", trainX.min(), trainX.max(), trainX.mean(), trainX.std())\n",
        "print(\"Test\", testX.min(), testX.max(), testX.mean(), testX.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMGKQEvyLmyf",
        "outputId": "969a6a3e-ea94-4f42-b491-2d3ac7936d68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (60000, 28, 28) (60000,)\n",
            "Test (10000, 28, 28) (10000,)\n",
            "Train 0 255 33.318421449829934 78.56748998339798\n",
            "Test 0 255 33.791224489795916 79.17246322228644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Normalize Images With ImageDataGenerator"
      ],
      "metadata": {
        "id": "p75Gw7jQL2S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape dataset to have a single channel because the ImageDataGenerator expects a numpy array of rank 4\n",
        "\n",
        "# trainX: (60000, 28, 28) => (60000, 28, 28, 1)\n",
        "# testX:  (10000, 28, 28) => (10000, 28, 28, 1)\n",
        "\n",
        "trainX = trainX.reshape((trainX.shape[0], trainX.shape[1], trainX.shape[2], 1))\n",
        "testX = testX.reshape((testX.shape[0], trainX.shape[1], trainX.shape[2], 1))"
      ],
      "metadata": {
        "id": "clu0QHTNLw8L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train\", trainX.shape, trainY.shape)\n",
        "print(\"Test\", testX.shape, testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQQiC6GwL4tL",
        "outputId": "698a3fdd-008c-40fa-b7e2-5a672731950e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (60000, 28, 28, 1) (60000,)\n",
            "Test (10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm scale of pixels\n",
        "print(f'Train min= {trainX.min()}, max= {trainX.max()}')\n",
        "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5MuroF-L6y9",
        "outputId": "18f23001-a6db-4bb0-abc8-0c317f5934eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train min= 0, max= 255\n",
            "Test min=0.000, max=255.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create generator (1.0/255.0)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# prepare iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "\n",
        "# 60000 / 64 = 937.5 ~= 938\n",
        "\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "\n",
        "# confirm the scaling works\n",
        "batchX, batchy = train_iterator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWo5PTQJMBKT",
        "outputId": "734b2eb0-af20-43f3-a118-4c0eba527742"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches train=938, test=157\n",
            "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Center Images With ImageDataGenerator"
      ],
      "metadata": {
        "id": "laWCjisbMW-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the mean of the pixel values and make sure all the pixels are distributed around it as if it were the new zero and the remaining values are positive and negative.\n",
        "\n",
        "# report per-image mean\n",
        "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
        "\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator Mean: %.3f' % datagen.mean)\n",
        "\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CST1ccQMIyT",
        "outputId": "7fb76e01-94e8-49ce-ba4c-6f3d7cc628b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Means train=33.318, test=33.791\n",
            "Data Generator Mean: 33.318\n",
            "(64, 28, 28, 1) -1.5882585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A better check would be to set the batch size to the size of the training dataset (e.g. 60,000 samples), retrieve one batch, then calculate the mean. It should be a very small value close to zero."
      ],
      "metadata": {
        "id": "bo2Zov5hNFsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n",
        "\n",
        "#display an image\n",
        "img2 = batchX[41]\n",
        "print(img2.shape)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "mV737jSjMrhC",
        "outputId": "fe6b9aa4-22fc-4ab2-9ceb-652b90bfba3c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) -1.9512918e-05\n",
            "(28, 28, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F5452B8C610>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACEElEQVR4nO2VP8hxURzHf+d6y3Pp+hPDTTHIwGCwKSWrFLdbTMqoZDQYDJKyKIqSVVlsBrIYKKUooqhzFxtFkiSl3Ge4Jb3+XM/z1Ns7PN/xe87v0/f0O79zAH71/4hl2clkwjDM/RLxPoUkSYqiKIq6dYLB4P3OP28SU6kUy7JSqZTn+e12a7fbBX+xWNxvRqI4nU6XTCZdLhcAIIR4ngcAm81WrVZpmr7Sv5DUbDbXarWPjw8AKJVKCCGn08kwTCQSMZvNm83mYZUItNFoXC6X8Xjs9/sBwGAwnE6nTCbjcrkkEkmr1RI96ANxHIcxjsfjV8doNGKMMcb5fP47RAAIh8MColKpKBQKpVLZ7XYxxp1OR6FQPKsSb1Qul/N4PACw2WwQQhqNZrlc+ny+3W73zaR/5eU4rtfrvcgo6K172u/3EUIAQBDEarXa7/c/harV6kKhwPP8er1GCOn1eplMdjweX5SIjKlSqazX6zRNL5dLt9tdqVRUKlU0Gv1R0larde3M9dQPp+jdpIlEQqvVAkA0Gr3t9e2b8jWow+EIhUIEQRSLxel0KphyuRwhNB6PX0OfKp1OY4zn87nFYhEckiQ5jmu326K1T5MKrMPhcD6fTSaT1+sdDAYAMBqNRKFPGzWbzaxWq0qlajabV7NcLmezWVHo0zFVq9WBQCAWi/E8PxwOZTLZw5/jV/9InyV4yQyMrM8DAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kZKCiWdrNKzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}